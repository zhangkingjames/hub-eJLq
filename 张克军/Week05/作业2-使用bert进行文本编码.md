# 使用 BERT 进行 FAQ 语义匹配的技术方案

## 1. 我们要解决什么问题
用户提问后，系统要从 FAQ 库里找到意思最相似的问题，把对应的答案返回给用户。  
FAQ 库每个知识有“标准问”和最多 200 条“相似问”，这些都是匹配的依据。

## 2. 为什么不直接用传统搜索
传统的关键词搜索只能匹配字面相同的内容，用户说“办不了业务”和“无法办理业务”意思一样，但字不一样就匹配不到。  
BERT 能理解句子含义，把意思相近的句子识别出来，所以我们用 BERT。

---

## 3. 核心思路：句子转向量，算距离
每个句子用一个数学上的“向量”表示（可以理解成身份证号），意思越像的句子，向量越接近。  
用户提问来了，也给它算一个向量，然后去库里找最接近的几个，取出答案。  
整个过程分**离线建库**和**在线匹配**两大块。

---

## 4. 离线阶段：给 FAQ 建向量库

### 4.1 选模型
使用 **Sentence-BERT**，这是专门把句子变成向量的模型，已经预训练好了。  
具体选 `paraphrase-multilingual-MiniLM-L12-v2`，支持中文，速度快，输出 384 维向量，够用。

### 4.2 处理 FAQ 文本
从数据库里读出每条 FAQ 的“标准问”和所有“相似问”，把每一条都当成独立的句子。  
句子输入模型，模型输出 384 个浮点数，这就是句子的向量。  
（技术叫“均值池化”，可以简单理解为把句子中每个字的意思平均一下）

### 4.3 存进向量数据库
把所有 FAQ 的向量都存到**向量数据库**（比如 Faiss、Milvus）里，并给它们建立索引——就像给书编目录，将来找起来快。  
同时还要存好每个向量对应的 FAQ ID、答案原文、类目等信息。

---

## 5. 在线阶段：用户提问实时匹配

### 5.1 实时编码
用户输入一句话，系统用**完全相同的 Sentence-BERT 模型**，也把它转成 384 个数字的向量。

### 5.2 相似度计算
向量库里的“余弦相似度”可以给两个向量打分，0~1 分，1 分代表完全一样，0 分代表毫不相关。  
我们设定一个阈值（比如 0.85），**高于这个分才算匹配成功**。

### 5.3 召回答案
向量数据库根据用户问题的向量，快速找出库里分数最高的几个候选（比如取前 5 个）。  
把低于 0.85 分的扔掉，剩下分数最高的那个 FAQ ID，取出它的答案，返回给用户。  
如果全都不够分，就回复“没理解您的问题”或推荐几个常见问题。

---

## 6. 几个重要的落地细节

### 6.1 离线在线用同一个模型
模型一旦选好就不再改动，离线建库和在线编码必须是**同一套参数**，否则向量没有可比性。

### 6.2 增量更新
客服每天可能新增 FAQ，不能每次都重建整个库。  
做法：新增 FAQ 实时转成向量，插入向量数据库；删除 FAQ 时同步删除对应向量。  
通常每天凌晨做一次全量重建，保证一致性。

### 6.3 要不要大模型
**不是必须的。** Sentence-BERT 已经能很好完成任务，速度快、成本低。  
大模型可以用在“无匹配时用生成式回答”的辅助场景，纯 FAQ 匹配用 BERT 足矣。

### 6.4 持续优化
每天记录“用户问了但没匹配上”的问题，运营人员给这些问题补充相似问，下次就能匹配上。  
积累足够数据后，可以用这些数据把 Sentence-BERT 模型微调一下，让它更懂你的业务。

---

## 7. 总结

| 步骤 | 做什么 | 用什么技术 |
|------|--------|------------|
| 1 | 把 FAQ 里每条标准问/相似问变成向量 | Sentence-BERT |
| 2 | 把向量存起来并建索引 | 向量数据库（Faiss/Milvus） |
| 3 | 用户提问也变成向量 | 同上模型 |
| 4 | 找最相似的几个向量 | 余弦相似度 + 近似检索 |
| 5 | 过滤低分，返回答案 | 阈值（比如 0.85） |
